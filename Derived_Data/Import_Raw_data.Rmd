---
title: "Import Raw Data From Text File"
author:  "Curtis C. Bohlen, Casco Bay Estuary Partnership"
date: "7/28/2020"
output:
  github_document:
    toc: true
    fig_width: 7
    fig_height: 5
---

<img
  src="https://www.cascobayestuary.org/wp-content/uploads/2014/04/logo_sm.jpg"
  style="position:absolute;top:10px;right:50px;" />


# Introduction.
The limited metadata availalbe to us based ont ehdata provided by GZA suggests GZA prvided dat in the spreadsheets making certain assumprtions about how to handle non-detects.  in aprticular, they appear to have followed the convention that replaces a non-detect with one half of the applicable detection limit. 

We wanted to explore the structire of the raw data to determine if we could use a more sophiticated approach to handling detection limits, but to no avail  Unfortunately, there is no metadata provided for these , so it is nearly impossible to make good use of them.



# Load Libraries
```{r load_libraries}
library(readxl)
library(readr)
library(tidyverse)

library(bigreadr)
```

# Load RawData
The challenge here is that the  file is huge, and it won't all fit into memory, so we need to read this in parts and then assemble a final data set.

```{r load_raw}
sibfldnm    <- 'Original_Data'
subfldnm    <- 'omitfromgit'
subsubfldnm <- 'Raw_EQuIS_Data'

parent      <- dirname(getwd())
sibling     <- file.path(parent,sibfldnm)

targetfldr <- file.path(sibling, subfldnm, subsubfldnm)
```

We want to read this in as pieces.  The bigreadr package can parse afile into a list of dataframes.  This is a convenient approach.  By default, this would still require all parts of that list to be included in the current workspace.  But the function allows a .transform argument which is a function to change each subpart of the dataframe.  We use that here to discard unwanted data, by dropping sonde, pressure, and weather data.

```{r}
stripsonde <- function(df) {df %>% filter(! (task_code == 'Sonde Data' | 
                                             task_code == 'Pressure'   |
                                             task_code == 'Weather'))}
```

The following code crashes the first time it is run, but works fine on subsequent runs.

```{r} 
fn    <- '20190805_dt_sample.txt'
fpath <- file.path(targetfldr, fn)
dflist <- big_fread1(fpath, every_nlines = 5000,
                     .transform = stripsonde)
```

```{r}
xtabs(~task_code, data = dflist)
```

# Remove Empty Data Columns
```{r}
not_all_na <- function(x) any(!is.na(x))
dflist <- dflist %>% select_if(not_all_na)
```


```{r}
cat(names(dflist))
cat('\n\n')
summary(dflist)
```

Variable Name     | Interpretation
------------------|------------------------
facility_id       | Only a single value....
sample_id         | Too many to show
sys_sample_code   | Combines site, date and "H" and "P" codes, sometimes other details
sample_name       | Perhaps the original name on the sample sent to the lab?
sys_loc_code      | Site Codes
sample_source     | Only a single value "LAB"
sample_type_code  | "N" and "FD" 
sample_date       |
remark            |
task_code         | "Baseflow", "Stormwater" and "Spring Melt"
matrix_code       | Only a single value -- "WS"
custom_field_1    | Apparently the parameter description or code.  Some look like CAS numbers, others are words.
custom_field_2    | Apparently the value
custom_field_3    | Units, with some inconsistencies, especially regarding capitalization.
custom_field_4    | Y N
custom_field_5    | Not sure. Look like maybe values in different units?  Detection Limits?
ebatch            |      
task_code_2       | Name of the Parameter, in English
euid              | An apparently sequential (?) ID number

# Remove pointless data columns
```{r}
dflist <- dflist %>% select(-facility_id, -sample_source, -matrix_code)
```

```{r}
unique(dflist$task_code_2)
```




```{r}
ggplot(dflist, aes(custom_field_2, custom_field_5, color = custom_field_4)) + geom_point() +
  geom_abline(slope = 1, intercept = 0)
```

